In this paper we have presented a critical review and an experimental comparison of the most concrete and efficient Frequent Pattern Mining Hadoop and Spark Implementation. Because of the double nature of the topic, including both data mining and big data domains, we have analysed the approaches with dimension typical of the two environments. Therefore, we have firstly described the underlying centralized algorithm from which the distributed implementations were inspired, and their legacy to the distributed counterparts such as search space exploration strategy and the type of data distribution enhancing the effectiveness of the mining. After that, we have described the approaches taking into account communication cost and load balance, typical of distributed environments. These features are often underestimated but represents very critical issues in all the Big Data applications: the problem is very hard and cannot be reduced to a pure exploiting of the computation resources of big clusters of machines.
After that, we have benchmarked the algorithms with different type of mining problems. We have studied the performance of the approaches dealing with different values of minimum support, different transaction length, different expected patterns length and different number of transactions. We have also evaluated the algorithms dealing with a real use cases and, finally, from the point of view of load balancing.
In this way, we tried to support the reader in the choice of the algorithm which best fits his requirements and use case features.
In general, as detailed in Subsection \ref{lesson} the most suitable approach is related to the use case. DistEclat and BigFIM proved to be very fast when they not run out of memory. MLlib PFP, instead, is strongly affected by the average transaction length while Mahout PFP demonstrated to be the most reliable only when the minsup value is deepened and the attributes number is very high.

 
  
%    The experiments showed that DistEclat has the best performance when it does not run of memory. In addition has very good performances when dealing with a high number of attributes or long expected frequent patterns. DistEclat proved to be very fast but it likely runs out of memory when dealing with huge amount of data. Mahout PFP showed very interesting performances in almost all the use cases, except when dealing with very low minsup values. MLLib PFP, instead, proved to be most reliable approach when dealing with almost all the use cases. It showed some memory issues with very sparse distribution but it proved to be very efficient in the real life use cases. Since it also demonstrated to be the very balanced in the distribution of the work among the nodes, we consider it the most promising approach for general use cases. In addition, it is the newest algorithm of the tested group of approach, so it is also the least mature and will be likely improved by MLlib community. 
%For long transactions or sparse datasets, instead, we consider BigFIM the most suitable approach, even because of its fair load balance behaviour.