The main target of this review is to build a structured comparison among the most spread distributed frequent itemset miner. For this reason, a set of criteria is needed to better organize the comparison. Among the selected dimensions we have included two groups of features.

The first set is strictly related to the centralized frequent itemset algorithms from which the distributed implementations are based. It is very rare indeed to find an approach designed from scratches to be distributed or parallelized. Often, the main contribution introduced in the domain is the implementation of well-known technique to distributed environment. Thus, the main research efforts are moved from the algorithm design to:
\begin{itemize}
\item the distribution of tools or algorithms that were not design to be distributed (i.e. splitting the computation load into more than one node). In addition, data mining algorithms are often characterized by the need of a full knowledge of the problem or data. In other words, data mining problems are often not "embarassingly parallelizable". This issue makes the distribution very challenging.
\item a "smart" transposition to distributed frameworks, exploitating the advantages and top features of the platforms. For instance, exploiting data locality in MapReduce-based implementations provides a fundamental performance boost. Another example is the optimized "shuffle \& sort" phase which represents the unique phase in which data can be sent to other nodes. Transposing an algorithm into MapReduce can be very challenging because of its strictness (one of the advantages of Apache Spark over Hadoop is its greater flexibility).
\end{itemize}
Hence, the underlying centralized algorithms are very important to describe and evaluate the scalable approaches. Some of their features are directly inherited by the distributed algorithms. Specifically, we have selected:
\begin{enumerate}
\item Search space exploration strategy.
\item Data distribution. 
\end{enumerate}
This couple of attributes, directly inherited from the underlying approaches, characterizes the candidate itemset generation~\cite{goethals2003survey}. The performance of the algorithms that adopt a breadth-first exploration is negatively affected by a large average transaction width, because more candidate itemsets must be examined~\cite{KumarBook}. Since average transaction width is strongly related to the input data distribution, there exists a relationship between the exploration strategy and the input dataset distribution. For example, Apriori-based algorithm~\cite{Agr94}, detailed in Subsection~\ref{bigfim} , with their breadth-first exploration approach, better fits datasets characterized by sparse distributions, i.e. low correlation among patterns and high item cardinality.

The second set of evaluation criteria is related to the distributed nature of the processing. They are often undervalued in the data mining context but represent very critical issues~\cite{afrati2012designing},~\cite{leskovec2014mining}.
\begin{enumerate}
\item Communication costs: this issue it may be underestimated in distributed algorithms, but they represent the most likely bottleneck of a distributed system~\cite{sarma2013upper}. In the design phase, most of the researchers focus only on the computational costs and the need to split them among the nodes. The result is that a great amount of data is sent through the network, making communication cost overwhelming computational one. In addition, as already mentioned, many data minings algorithms were designed for centralized systems, ignoring these kinds of factors. However, the data locality paradigm is one of the reason of the effectiveness of distributed platforms such as Hadoop or Spark. Thus, the implementations in this review will be evaluated also through the care or attention devoted to this aspect.
\item Load balancing: since one of the main motivation behind the development or the utilization of a distributed approach is to decrease the execution time, load balancing is a central aspect to evaluate the efficiency of a distributed approach. An unbalanced load undermines the advantages of a parallel environment: the overall execution time is that of the slowest, most loaded node. In a fully unbalanced environment, the worst case scenario leads to no benefits from parallelization while still incurring all the overheads of coordinating a rather complex distributed system.
\end{enumerate}
A review of the evaluation criteria can be found in Table~\ref{tab:example1}. After a qualitative review in Section~\ref{algorithms}, in Section~\ref{experimental} an experimental performance evaluation will be provided, based on a set of experiments on both synthetic datasets.